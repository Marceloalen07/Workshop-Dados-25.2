# -*- coding: utf-8 -*-
"""Sobrevivencia_titanic

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13EEUPGo6ivdgeyK23cOj-kxncXiqbpcX
"""

#2. Obter os dados
import pandas as pd
import seaborn as sns

df = sns.load_dataset('titanic')
print("Dimensão:", df.shape)
df.head()
# opcional: salvar localmente
df.to_csv('/content/titanic.csv', index=False)
#3. Explorar os dados
print(df.info())
print("\nContagem de nulos por coluna:\n", df.isnull().sum())
print("\nDistribuição do target (survived):")
print(df['survived'].value_counts(normalize=True))
df2 = df.copy()
 #4. Tratamento dos dados
# feature engineering: tamanho da família / is_alone
df2['family_size'] = df2['sibsp'].fillna(0) + df2['parch'].fillna(0)
df2['is_alone'] = (df2['family_size'] == 0).astype(int)

# Selecionar colunas úteis (exemplo)
features = ['pclass', 'sex', 'age', 'fare', 'embarked', 'family_size', 'is_alone']
df2 = df2[features + ['survived']]

# Algumas conversões (se necessário)
df2['pclass'] = df2['pclass'].astype('int64')
df2.head()
#5. Separar Base de Dados em Arrays
X = df2.drop('survived', axis=1)
y = df2['survived']
print("X shape:", X.shape, "y shape:", y.shape)

#6. Técnicas de Pré-processamento
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler

# detectar tipos
num_features = X.select_dtypes(include=['int64','float64']).columns.tolist()
cat_features = X.select_dtypes(include=['object','category','bool']).columns.tolist()

num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

cat_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))
])

preprocessor = ColumnTransformer([
    ('num', num_pipeline, num_features),
    ('cat', cat_pipeline, cat_features)
])

# exemplo: testar preprocessor transform
X_trans = preprocessor.fit_transform(X)
print("Dimensão após transformação:", X_trans.shape)
#7 Dividir Base de Dados entre Treino e Teste
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
print("Treino:", X_train.shape, "Teste:", X_test.shape)
#8. Definir vários modelos e aplicar Treinamento
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import cross_val_score

# Pipelines completos (preprocessor + classifier)
pipe_lr = Pipeline([('pre', preprocessor), ('clf', LogisticRegression(max_iter=2000, class_weight='balanced'))])
pipe_rf = Pipeline([('pre', preprocessor), ('clf', RandomForestClassifier(random_state=42))])
pipe_gb = Pipeline([('pre', preprocessor), ('clf', GradientBoostingClassifier(random_state=42))])

models = {'LogisticRegression': pipe_lr, 'RandomForest': pipe_rf, 'GradientBoosting': pipe_gb}

# Cross-validation rápida no conjunto de treino
for name, pipe in models.items():
    scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)
    print(f"{name}: CV acc = {scores.mean():.3f} ± {scores.std():.3f}")

    #9. Validar o Modelo
    from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay, roc_auc_score

# usar o melhor modelo encontrado (ou escolher manualmente)
model = best_model  # a variável do RandomizedSearchCV; se não usou tuning, escolha pipe_rf, pipe_lr, etc.
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print("Acurácia no teste:", acc)
print("\nRelatório de classificação:\n", classification_report(y_test, y_pred))

# Matriz de confusão gráfica
import matplotlib.pyplot as plt
ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)
plt.show()

# ROC AUC (se disponível probabilidade)
if hasattr(model, "predict_proba"):
    y_proba = model.predict_proba(X_test)[:,1]
    print("ROC AUC:", roc_auc_score(y_test, y_proba))

    #10. Salvar a Solução
    import joblib
joblib.dump(model, '/content/titanic_model_pipeline.joblib')
print("Modelo salvo em /content/titanic_model_pipeline.joblib")

# no Colab: baixar arquivo para sua máquina
from google.colab import files
files.download('/content/titanic_model_pipeline.joblib')  # irá iniciar download

